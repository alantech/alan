# 023 - Evolving the Syntax RFC

## Current Status

### Proposed

2024-05-09

### Implementation

- [ ] Implemented: [One or more PRs](https://github.com/alantech/alan/some-pr-link-here) YYYY-MM-DD
- [ ] Revoked/Superceded by: [RFC ###](./000 - RFC Template.md) YYYY-MM-DD

## Author(s)

- David Ellis <isv.damocles@gmail.com>

## Summary

Now that a POC of GPGPU in Alan has been achieved, getting the compiler fully working and the test suite passing is the goal. But there have already been some changes to the syntax with this new focus for the language, and making sure these changes produce a consistent, easy-to-learn, and powerful language that people would actually enjoy developing in.

This document outlines the new ethos behind the Alan language, and outlines modifications to the syntax based on that ethos and the constraints of current-day GPUs.

## Expected SemBDD Impact

If Alan was already at v1.0, this would be a hard v2.0 break, but more along the lines of Perl 6 effectively breaking the language entirely.

## Proposal

The driving ethos behind Alan has always been to make a language that empowers developers to "punch above their weight class" in terms of features while also reducing the long-term maintenance burden by minimizing boilerplate code that obscures the important logic, while also preventing broken code from being written in the first place. The problems Alan v0.1 was mostly solving were those seen at Uber where growth was putting pressure on the services and therefore on the engineering teams to keep them running. These aren't drivers for adoption of a new language, though, as they're problems of success and when successful you can pay for more developer time to resolve them.

A driver to adopt a new language is when you can accomplish something new, or can accomplish the same thing far more easily than before.

### Why is CUDA not good enough?

There's currently a high barrier to entry for GPGPU programming, with harsh trade-offs whichever path you take, so many developers simply never reach for it when they could, instead firing up a cluster of CPU-only servers and dealing with distributed systems and the pains (and costs) there.

On one end, you have the proprietary languages CUDA and ROCm by nVidia and AMD, respectively. These are both extensions of C++ adding new concepts to the language, allowing you to write the code that will run on the GPU in a way that feels *similar* to C++, but isn't C++, a kind of C++++. But in reality ROCm is kind of dead in the water, as any application written for it requires a special set of kernel extensions installed to run at all, while CUDA-compiled binaries can just be distributed with a runtime dynamic library that hooks into the standard nVidia driver (which does also make its own hooks into the kernel, but at least you can be sure users of that hardware already have the necessary kernel driver code). In any case, these proprietary languages are not compatible with all GPUs, but only certain ones with certain features [gated by the particular GPU model you're running on](https://docs.nvidia.com/deploy/cuda-compatibility/index.html#faq), which does give them advantages in runtime performance, but means that you have to narrow the scope of target machines dramatically, making these language potential candidates for applications deployed to a data center, as there is usually only *one* collection of machines that will run the code, and so the language and hardware can be chosen in tandem to meet the developer needs in this situation, but this code cannot be easily run by anyone else (less so for CUDA than ROCm, but still mostly true).

On the other end, you have the standard GPU APIs. Traditionally just DirectX and OpenGL, but with the fragmentation of OpenGL's API from all of the extensions necessary to get it near modern DirectX's performance, OpenGL has been mostly relegated to a legacy API with two new APIs, Vulkan and Metal, taking its place; so there are now three major GPU APIs you have to target, one for each major OS (DirectX for Windows, Metal for macOS/iOS, and Vulkan for Linux/Android). All three *can* run OpenGL still, but the code to do so is often super branchy to probe for which extensions are available to accomplish what you wish to, such that it may be less work to just write code for each of the three instead, especially since you're *likely* to get better performance using the more native API.

In the middle, we have OpenCL, WebGL, and WebGPU. I'm grouping OpenCL together with the Web* APIs because the GPU code you write still needs to be a "shader" in a different language than the host programming language, though OpenCL has essentially the both of the downsides of the prior two groups: there tends to be weird driver issues to get OpenCL working on your machine for your hardware of choice, and it is considered a legacy technology that doesn't perform as well as CUDA or ROCm.

WebGL provides an API very similar to OpenGL ES 3.0, which is even more restrictive than OpenGL, and has even worse performance trade-offs because of this, but has higher compatibility, with libraries for all platforms available to run it (so most WebGL code is actually run in a DirectX translation layer). Cross-compatibility is best with WebGL, while the overall performance is the worst of them.

WebGPU is a newer project that produces an API inspired by Vulkan, Metal, and DirectX 12, meant to translate more easily and cleanly to them with a smaller overhead than WebGL (but not zero overhead). It works on almost every platform (only Firefox doesn't yet support it), and has the conceptually cleanest API of any of the options discussed so far for GPGPU (in my opinion), though it still requires GPU work to be written in the `wgsl` shader language. This is mostly because of how narrow and restrictive GPGPU programs are.

So, for a developer that wants their code to run on many users' devices, they need a guarantee that the code will at least *run* on their machine, regardless of how fast they can get it. Because this has been *so difficult* to do effectively, most developers have not touched it. Instead, the majority of end user software that ends up doing GPGPU computing does so through a restrictive framework like PyTorch, where a small group of developers do the hard work to get GPGPU actions performant and then you glue their primitives together. This is nice if the framework provides the primitives you need, but not great, otherwise. It also reduces the optimization possibilities, as different framework calls may make sense to be merged together while the framework may not be able to because of language semantics, or could potentially be eliminated if compile-time knowledge of the program could determine that certain operations together cancel out as a no-op.

Ideally, with a deeper language integration it would be possible to automatically convert between sequential, CPU parallel, and GPGPU either at compile time or run time and the developer simply gets this "for free." And they wouldn't have to worry about which hardware + OS combination their users are running, it just works. This is what Alan v0.2 is about.

### The Scope of Alan v0.2

Alan has always been a "batteries included" language, and that continues with v0.2. Backend deployment, monitoring, and auto-scaling has been removed, as well as distributed shared memory, but the `alan` binary being heavyweight and taking on more responsibilities than just compilation will remain. Alan v0.2 will include:

* The Compiler
* The Standard Library
* The Package Manager
* The Test Runner
* The Language Server

with potential follow-on features such as an interpreter, a debugger, a linter, and a cloud deployment tool.

The compiler will be focused on compiling to Rust, but will have a path to compile to JS + WebGPU so that the compiler can be transpiled to WASM and run in the browser (it unfortunately can't generate Rust to then transpile to more WASM because the Rust to WASM compilation is by the Rust toolchain, which itself is based on Clang, which doesn't have a WASM transpilation, as far as I know). This will help keep the standard library portable to multiple targets and should ease things if we ever replace Rust with another path, like a self-hosted compiler written in Alan.

The standard library will be focused on compute, but IO in the form of a web server is definitely desireable. Baking in [`hyper`](https://hyper.rs) or similar is probably the way to go, there. With the `binds` syntax, it should be pretty straightforward. I won't try to guess the exact set of things going into the standard library, but I see no problem with "adopting" a popular library into the standard library (if the author(s) of said library are fine with that and if the popular library is generalized enough to make sense as the de facto way to accomplish something). Because only the code you actually use gets compiled into the binary, the surface area for attacks will still stay low for most applications because a forced jump into another function can't happen if that function doesn't exist.

The package manager is going to have some impact on how compilation works, as an Alan package may end up pointing at a Rust package that it's binding, and that will alter the `Cargo.toml` to be used; the current hardwired approach to the set of Rust packages that the standard library uses will have to be adjusted. (Similarly, for JS transpilation, it might point at an NPM package it depends on, and ideally every package that binds would include packages for both, or include `.rs` and `.js` files that only depend on their own languages' standard libraries.)

A centralized dependency listing file (like `Cargo.toml` and `package.json`) still makes sense to me, but I don't know if the Alan v0.1 approach of it being an Alan source file itself makes sense or not. Rust, Node, Python, etc, all use declarative files for this, but Ruby does use a DSL in Bundler's `Gemfile` (it's basically ruby with some extra functions already in the global scope for you), and complex configuration needs tend to push these configuration files into awkward directions with no (good) way to get feedback from your IDE on if you're doing things right or not. Writing Alan code that depends on a special standard library for package management might seem weird to people, but it definitely would be the most flexible for features like library-specific access controls for improve security that I also want to explore.

The test runner is a no brainer. Rust has it, I have no idea why it took Node.js until [version 20](https://nodejs.org/docs/latest/api/test.html) to do the same but Node.js has it. It just makes sense to have an integrated way to write and run tests. I already have plans for the special syntax testing in Alan will use. More on that later in this document. :)

There is [a Rust library for the language server protocol](https://github.com/ebkalderon/tower-lsp) so adding LSP support will be simpler than it otherwise would have been. The compiler is already structured to make usage in an LSP amenable; the file parsing goes into the "Program" data structure that indexes the various components of the code to be compiled. The LSP mode would stop at this indexing stage and then answer "questions" about the codebase using the same mechanism. This can be flipped on it's head and used for faster incremental compilation -- the compiler could look for a running LSP instance and tell it what to execute based on its already parsed state. So baking the LSP into the compiler isn't just a nice-to-have, it should produce a better development experience overall.

And of course, there are also the syntax changes based on what worked or didn't work in Alan v0.1 as well as due to the change in focus for the language.

### Alan v0.2 Syntax Changes

Because the syntax of Alan is going to be constrained by the capabilities of compute shaders, let's go over their limitations first:

* The base types are just `i32`, `u32`, `f32`, and `bool`.
* There are built-in types for vectors (meaning fixed-length arrays of 2 to 4 elements, the opposite terminology of Rust)
* There are built-in types for matrices (effectively vectors of vectors IxJ, 2 to 4 for each (setting 1 for either dimension makes it a vector again))
* You can make structs out of these and other structs.
* There are built-in arrays for any of the above, but they *can't* be allocated within the compute shader, only beforehand on the CPU-side, meaning they are variable length but not varying length like most arrays (again, inverse terminology of Rust)
* You can have functions, but these functions cannot be recursive.
* You do have loops, and it's on you to make sure you exit. Also most GPU drivers impose a timeout of [2](https://stackoverflow.com/questions/68885074/metal-compute-function-causes-gpu-timeout-error)-[5](https://forum.unity.com/threads/compute-shader-timeout.311020/) seconds for total runtime for a shader, so *really* long-running work needs to be split up.
* Multiple kinds of address spaces that have different access controls and atomicity guarantees, with special built-in functions to work with the atomics.

The constraints are pretty tight, with the entire `wgsl` language focused on a narrow set of use-cases. Instead of making the entire language compilable into compute shaders and therefore impose all of these constraints on the developer, having a collection of types to work with and explicitly move some of the work onto GPU side will help keep the ergonomics better.

The test implementation of GPGPU in [the Alan repository as this is written](https://github.com/alantech/alan/tree/6d3521656512b5a897ad7d1c21aaa98b079e94f9) requires instantiating a `GPU` object that sets up the default GPU on the machine, from which you can create Buffer objects that allocate memory on the GPU, with or without initialization. Then you can create a `GPGPU` object that includes the compute shader code you want to run and the set of buffers in the order the compute shader expects them, and then pass that to a `run` method on the `GPU` to execute. Finally, you can `read` the `Buffer` to get the results back out to the CPU side.

This is already a bit easier than the default `wgpu` API, but it's still pretty manual and requires you to write code in a different language whose conventions may not be very clear (definitely weren't to me for a while). But by introducing a collection of types that combine with each other to describe an AST that can then be compiled into this shader language, it should be possible to accomplish something like [gpu.js](https://gpu.rocks/#/) without the negatives of the interior block disobeying so many language conventions despite looking like it's part of the language.

This is because "regular" types and functions will evaluate on the CPU side ahead of time to then produce an output that is then combined with the "GPU" types that construct the AST, with special functions to make the merging of these two transparent. Something like `gpuArray[i] = gpuArray[i] + 5` would translate, step by step, first into `gpuArray[i] = add(gpuArray[i], 5)` where the signature is `fn add(GpuI32, i64): GpuI32`, then `gpuArray[i] = add(gpuArray.get(i), 5)` with `fn get(GpuArray<GpuI32>, GpuU32)` and then `gpuArray.set(i, add(gpuArray.get(i), 5))` with `fn set(GpuArray<GpuI32>, GpuU32, GpuI32)`. This would internally take the arguments to that `set` and attach them to an array of actions on the input array, which internally would have a shared counter of operations between all types that were constructed at the beginning of this callback function's running, allowing actions across buffers to be properly ordered in the output once the callback function has finished execution, and then serialized into the correct shader code.

Note that the right-hand-side `gpuArray[i]` was converted into a `get` method call, while the left-hand-side was converted into a `set` method call, "ignoring" the `=` in the statement in the middle, turning the whole thing from an assignment statement to a side-effect function call graph. One of the advantages of a new language is that the syntax can be whatever we want it to be. :) Well, it still needs to make *sense* to end users, so we can't get too carried away, but this need for the language to flex the definition of some core pieces of syntax is both why a new language is needed and why this can't just be grafted onto existing languages.

This is particularly true of conditionals. We need to be able to change the behavior of conditionals when branching on a GPU type instead of a CPU type so we can generate an AST for both branches of the conditional. This is the reason why a new language is required for this, rather than a framework in an existing language. The plan is that `if condition { ... } [else ...]` will be converted into `cond(condition, fn { ... } [, fn { ... }])` under the hood, with `bool` and `Gbool` being the only two provided implementations of this `cond` function at runtime. Then the implementation of `cond` for booleans will simply be a Rust macro to transform it back into the standard conditional syntax, while the GPU boolean type will splat out AST nodes for both branches, basically evaluating both paths to produce the two AST branches to generate the output wgsl code to run. Similar things will be necessary for loop constructs (but more on that later).

There are also features of Alan v0.1 that are highly desirable to keep around. First and foremost are all of the conveniences surrounding functions in Alan. Function dispatch is based on the input arguments as well as the name of the function, which enables a lot of things, such as not needing class syntax to handle multiple functions with the same name, which then makes method-style syntax automatically enabled for all functions and types. Then operators just being functions similarly simplifies things, making it possible to add operator logic to your own types by simply defining the right functions. In Alan v0.2 this is going to be expanded to `=` as an operator for the `set` function, as described above.

Beyond that, the type system made generalized functions more possible by allowing interfaces to define input types, so any type that passes the interface can be used to generate the actual code that will be called. It also was somewhat inspired by Rust's type system, but improvements will be made to it for Alan v0.2. After some study of the [Curry-Howard Correspondence](https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence) and some of its implications, the new type system will be derived from the ground up based on principles from it. First, because the correspondence between mathematical systems links type systems and lambda calculus, it's more clear that type declarations are effectively a compile-time language to describe the structure and constraints of what can be stored by a variable of that type.

* There's the basic `void` type that doesn't store any data, but is useful for representing when a function doesn't return anything, or the lack of a value on an `Option`-style type.
* There's a `never` type that never returns (to represent process exit and/or infinite loops). Because Alan will match many of the constraints of compute shaders to make sure code re-use within a GPGPU context works in the language as much as reasonably possible, this means that recursion is still disallowed, and will expose looping constructs, but with limits on iteration count, so the `never` type will not be used by Alan.
* There's "product types", which are basically structs and tuples. This name comes from how the possible values that can be represented are the product (multiplication) of each component type's possible value counts to each other. Eg, a tuple `u8, bool` would have `256 * 2 = 512` possible values. Structs in this view are simply tuples with user-provided labels for the fields rather than automatically derived ones from the order of the fields.
* There's "sum types", which are like Rust's enums. This name comes from how the possible values that can be represented are the sum (addition) of each component type's possible value counts to each other. Slightly modifying the prior example, a type `u8 | bool` would have `256 + 2 = 258` possible values (all of the possible numbers, *or* one of the two boolean values). I used Typescript's syntax here because it's more ergonomic than Rust enums, imo.
* There's "sigma types", which are types that are different types based on a compile-time value provided. They are called that after the sigma operator in math for summing all evaluations of a function across a range of input values, so they are like the sum type in that respect, but have a much higher "possibility space" more similar to product types in resulting value. All of this to say that Rust's static array types are an example of a sigma type. Eg `[u32; 5]` produces a fixed length array of 5 unsigned 32-bit integers. The complexity here is that you can *do math in your type system* here. You could have a generic type for a "C-style string" `type CString<L> = [u8; L+1]` that always zero-pads the C-string with an extra integer to store the zero byte. Types dependent on compile-time values like this can be used in other ways, as well. An `IncludeStr<F>` where `F` is the filename as a string could be used to compile-time embed another file as a string within your source code. And you can have conditional types based on compile-time booleans to conditionally compile parts of the code depending on operating system, CPU architecture, or execution environment (prod vs test).
* There's "pi types", which are types that vary based on the *value* of one or more of their input types. This is a more mind-bending type and I can't think of any statically-compiled type system that implements it, so I don't even have an example syntax to share, but you can get an example of one pretty easily with a one-liner recursive JS function: `const weirdNum = (n) => n > 0 ? [weirdNum(n - 1)] : undefined;` For `n = 0`, this returns `undefined`, while `n = 1` gives you `[]`, `n = 2` gives you `[[]]`, etc. So the output type is `undefined | Array<undefined> | Array<Array<undefined>> | ...` ad infinitum in Typescript's typing system, *but* you know exactly which one you're going to get from that based on the value of `n`. There's apparently research being done on how to potentially represent and use these sorts of types in a safe and performant way, but as far as I can tell, this kind of type would require the program to embed the type system and compiler with it so it can generate new functions as necessary to handle the type being generated to handle the value being generated, so it feels like only interpreted languages running in a VM could *possibly* use this, and I don't see how you would be able to ever safely use such types and be sure your code doesn't explode, or even just be practically safe against weird inputs from users that suddenly causes you to generate billions of functions. So this is the other kind of Curry-Howard correspondence type that will not be included in Alan (but it took me a *long time* to wrap my head around to be able to decide it's not worth it. It is interesting, though, that I can write super short code in Javascript that could not ever be written in Typescript, Rust, etc.
* And there's the "function type", which are exactly as you imagine, they describe functions, that can convert frome the input(s) into the output(s). While going through all of this, I realized that all functions are "simple" in this system, with only one input argument and one output argument, just `y = f(x)`, basically. How? Because sum types are structs/tuples and structs/tuples are identical to argument lists. So the input argument list is just a late-defined struct with the field names becoming the variable names in the body of the function and you're allowed to pass a tuple in the same order as the struct fields. Similarly, Go-style `(value, error)` return syntax is still just a single return type that's a tuple that you can destructure. Nothing special about it. The syntax for defining a function type in many languages boils down to `I -> O`. Conventionally it's always inlined declared with the function, including for higher-order functions that accept a function as a variable, which Alan will support, of course, but it's just going to be a place to have a type, so you could do something like define a generic identity function type `type Id<T> = id: T -> T` and then use it in something like `fn i32 Id<i32> = id` to define an `i32` function that returns the input directly if it was given an `i32` value. (I don't know if it will ever be worth it to actually do that, since `fn i32 id: i32 -> i32 = id` is not that much longer and is clearer and `fn i32 (id: i32) -> i32 = id` is clearer still, but using named function types for higher-order functions may improve legibility, eg `fn map<I, O> array: Array<I>, mapper: Fn<I, O> -> Array<O>` may reduce confusion versus `fn map<I, O> array: Array<I>, mapper: I -> O -> Array<O>` by removing the inner `->` arrow, but adding technically useless grouping parens `fn map<I, O> (array: Array<T>, mapper: I -> O) -> Array<O>` may be enough there.)

There are enough analogies here to make it clearer that a type system is a full programming language in itself, so if made fully Turing complete, the compiler could get stuck into an infinite loop trying to type your code. So we would similarly want to restrict what is possible here to make sure the compiler always finishes. The restrictions we place on Alan itself make sense, so for symmetry, it feels desirable to raise the possibilities for the types to the same as "normal" function code, similar to Zig's `comptime`, but this won't be done for two reasons:

1. It would require writing both a full interpreter and a compiler for the language in order to be able to compile the code, which is a lot of redundant work.
2. You're defining *types* at compile time for your program. A type system that can generate different types based off of an HTTP request to some random-ass server would be nigh-impossible to debug at best and likely a gaping security hole to exploit.

Now, as some of the examples showed above, being able to output non-type things, like embedded strings, or conditionally including parts of the code based on compile-time info like OS/arch/environment, are desirable, so these compile-time functions do need some extra power, but the scope should remain limited. With a `cfn` compile-time function type that can only use other compile-time functions to generate values we get an inner language within the language, where `type Foo<T> = ...` is just syntactic sugar for `cfn Foo T -> Type = ...`, though there may need to be some special casing such that basic type aliasing `type Foo = bool` is immediately evaluated.

Other features of Alan functions, such as aliasing functions to operators, method syntax, and argument-based function dispatch, will be available for these `cfn` functions (and therefore all usage of generic types), so the type syntax, such as `,`, `|`, `->`, etc will just be bindings for Java-style type syntax. The function type syntax for a map function, `fn map<I, O> array: Array<I>, mapper: I -> O -> Array<O> = ...` would break down to something like `fn map<I, O> Function<Struct<Field<array, Array<I>>, Field<mapper, Function<I, O>>>, Array<O>> = ...` where the `<I, O>` wouldn't be evaluated until an instance of `map` with specified inputs and outputs are provided, making generic functions `fn name<...>` further syntatic sugar for something like `cfn map<I, O> = fn Function<Struct<Field<array, Array<I>>, Field<mapper, Function<I, O>>, Array<O>> = ...` to define the function needed when it is invoked.

This is *mostly* going to be theoretical, though, as most of the time you will not need a generic function in Alan. Using an interface as a type will effectively automatically create a set of functions for each type the interface matches (though in reality it would be lazily evaluated based on usage), so you can just go with something like `fn map array: Iterable, mapper: Any -> AnythingElse -> Iterable` (where both `Any` and `AnythingElse` are both empty interfaces, but therefore allowed to be different types) and it should work without needing to explicitly specify the input and output types when calling it. Generic functions are only necessary when one of the types involved in the output of the function call cannot be derived from the input types, so mostly for constructor functions of generic types. Eg something like `fn Array<T> void -> Array<T> = ...` / `fn Array<T> () -> Array<T> = ...` (empty parens in a type should resolve to the `void` type).

To implement conditional compilation, all top-level statements (`import`, `export`, `const`, `type`, `cfn`, `fn`, `interface`, `operator`) will also optionally be "generic", but with only one fixed generic property, a compile-time boolean, so `fn` is equivalent to `fn<true>`. Then with some boolean compile-time operators can allow things like `fn<Os == "Linux">` (or perhaps `fn<Os<"Linux">>` or just `fn<Linux>`, depending on how much we want to pollute the root scope) and `fn<Test>` to indicate a function that should only exist when running tests. Because of how function resolution works, if there are two functions with identical signatures the most-recently-defined function wins, so if you define `fn main void -> void = ...` (hmm, `void -> void` / `() -> ()` may be the "default type" if you don't provide one for a function?) and `fn<Test> main () -> () = ...` after it, then you have a "normal" main function in normal compilation and the test main function under the test compilation.

Since method syntax is just syntactic sugar on top of writing the input value to the function in Alan v0.1, we can extend it by taking advantage of how it's just referring to the "beginning of the tuple" and "the rest of the tuple" to generalize this syntax, such that `foo(bar, baz, bay)` could be equally written as `bar.foo(baz, bay)`, `(bar, baz).foo(bay)`, and `(bar, baz, bay).foo`. Where you split the tuple doesn't matter, so you can write whatever reads the clearest.

We can take that a step further (eventually) by having another function calling syntax where you refer to the struct fields by name, to allow you to call them out-of-order like Python allows, so `foo(first: bar, second: baz, third: bay)` could be a way to call the function, but also `foo(third: bay, second: baz, first: bar)` should work despite the backwards ordering, and then with that you can `(second: baz).foo(first: bar, third: bay)` and gain method syntax for even out-of-order calling, not requiring you to write effectively aliases for functions changing the order of the arguments to be able to use it in method syntax. I don't think this should allow for a mix of the two calling syntaxes, though; you need to choose between struct-style and tuple-style function calling, or this will become a parsing nightmare.

You'll note that nothing about variable ownership is in this language despite being built on Rust. This is because, by having no recursion and no directly-accessible threading, function call can be pass-by-reference and just work. I probed on Mastodon about having an explicit call syntax indicating mutable versus immutable references but this was received poorly. Denoting mutability in the function definition, as Rust does, is something I may have to add, but I am now thinking that mutable/immutable references will be tracked silently within the compiler based on how you use the provided variable in order to generate the correct Rust code, rooted on the bound function's own mutability for the arguments it operates on. Meanwhile the return value of a function must always be an owned value for the function that will accept it back. This does mean there are certain situations where Alan will need to clone values that Rust wouldn't have to, but I think the reduced developer overhead will be worth it for the target audience (if you didn't want to write GPGPU code within the same language as your CPU code without needing to worry too much about how that's actually accomplished, then you'd probably be fine with just writing wgsl shaders and managing the GPU yourself in Rust). I find myself often in that target audience bracket, when writing services or end-user application code, you want to focus on your job, not how to manage memory.

Last, but not least, looping back to loops. Alan v0.1 didn't have them except through methods on arrays and other iterable types. This is probably all I will implement *at first*, but I am tempted to provide more traditional constructs if users clamor for it, or are confused by their absence. They won't be 100% like their "regular" Algol cousins, since those allow for infinite looping, which does not work at all in a GPGPU context and I just consider a bad idea in general. So, the following is not guaranteed to be added, but it might be if I am persuaded.

There are 5 control flow syntaxes in `wgsl`: `if`, `for`, `while`, `switch`, and `loop`. The first three are nearly identical to the C control flow syntaxes (you just don't have to wrap the conditional in parens). The `switch` statement is more restrictive than in C (always requires a `default` path, no fallthrough between cases) making it just syntactic sugar around `if`. The `loop` syntax, similarly, is a very thin syntactic sugar on `while true { ...` or `for (;;) {` (the latter *does* work in `wgsl`, unfortunately), requiring a `break` to exit the loop. These are... not great. The `for` loop is itself just syntactic sugar on a `while` loop, given that you can skip the counter variable initialization, comparison, and increment just like in C, so `wgsl` in reality only has `if` and `while` (or perhaps `if` and `loop` with `while` being a `loop { if condition { break; } }`, many different ways you can coalesce this concept internally). In the end it's the same thing, though; the only kind of looping in `wgsl` is an uncontrolled loop, and it's up to the developer to actually make sure the loop ends.

Syntactic sugar can be good if it buys you legibility or optimization possibilities, but syntactic sugar for the sake of syntactic sugar is just CoffeeScript. So, all loops in Alan need to have a known termination point. That could be determined at run time instead of compile time, but it needs to be knowable both to guarantee execution finishes and to make single-thread/multi-thread/GPGPU automatic trade-off possible. In terms of loops, there are roughly three kinds in real-world applications: loops that iterate a known number of times where the number is known at compile time, loops that iterate a known number of times where that number is known just before the loop starts, and loops that iterate an unknown number of times, but will abort past some tolerable maximum. The first kind are "unrollable" loops, and often the compiler will figure out whether or not it makes sense to unroll or leave the counter and conditional jump based on heuristics including the number of iterations and the size of the code involved. The second kind match up well with functional-style array operations: `map`, `filter`, and `reduce` all have a knowable-at-runtime number of calls based on the size of the array. This is also true of `for record in myArray {` syntax in many languages, but is *not* true of `for value in myGenerator {` despite the identical syntax. A malformed generator function would cause an infinite loop here despite the apparent assurance of the syntax. To be safer, you would need to declare a counter variable before the `for .. in` and `break` if the counter is somehow exceeded (probably logging an error to track in your bugtracker if ever hit). Loops that have an unknown number of iterations tend to be written as `while` loops where the conditional break involves some property of the data being looped over, such as the convergence of a Newton-Raphson numeric solver, but the condition should also pay attention to the number of iterations to prevent a failure to converge from causing an infinite loop, and it's up to the developer in most languages to make sure they remember to do that. There are also functional array operations that fall into this same situation, such a `findIndex` to determine the first index in the array that has the value in question and then stop, but it's automatically bounded by the length of the array and can never infinite loop.

For the sake of not making totally new keywords that would simply annoy people, if Alan get imperative-looking loops, it will implement a knowable loop count syntax `for .. in` and an unknown but bounded loop count syntax `while .. limit`. The `for .. in` in Alan will *not* accept generators/iterators (types with a `next` function), instead it will only accept Array-like types that have two functions implemented: `fn len(a: ArrayLikeType): usize` and `fn get(a: ArrayLikeType, i: usize): WhateverYouWant`. So you could make a "bounded generator" that knows what the maximum value can be, and has a way to get at intermediate values between `0..len`, which also implies that Ranges should work the same way. This doesn't mean an unbounded generator function is *impossible* (you could always create your own struct that houses the state of the generator and a `next` function that increments it and then returns the value requested), but either that struct housing the generator state also needs to house a value stating the maximum number of times you can call it and some way to (ideally cheaply) get at prior values, or it would need to be populated into an array by a prior loop that executed for a known range, which could just be something like `fn take(g: GeneratorType, c: usize): Array<GeneratorValueType>` so you could run `for val in myGenerator.take(50) {`. With this syntax itself being sugar for a `fn for(a: ArrayLike, f: fn(v: ArrayLikeGetReturnType))` it would similarly be possible to define something that automatically handled generators but would still require some looping limit baked into it, so that would not be encouraged.

The `while .. limit` syntax would look like a while loop, but essentially has a hardwired conditional and counter within it. `while delta < 0.01 { .. } limit 10` would allow up to ten iterations until it exits. The `limit usizeVariable` piece would be required, and would have an optional second block if the limit is reached `while delta < 0.01 { ... } limit 10 { ... }` to allow for code to run if hitting the limit changes things. This would be implemented by `fn while(c: fn(): bool, l: usize, body: fn())` and `fn while(c: fn(): bool, l: susize, body: fn(), limitHitBody: fn())` functions that could have it's behavior extended for other types. There's no `break` in either syntax because in the `for .. in` early exiting is not allowed, and in the `while .. limit` the conditional *is* the early exit indication. `while true { ... } limit 10` would basically be identical to `for _ in 0..10 { ... }`, but simplifying this syntax further (something like `loop 10 { ... }`) shouldn't be necessary (and including a syntax like that would also require adding another function that needs to be overrideable if you want to allow iterative operations with your type).

The standard implementation of these functions in Rust would simply be macro functions that recreates the same bounded behavior with Rust's own loop controls, for performance's sake (eg, `while delta < 0.01 { ... } limit 10` would first be transformed into `while(fn = delta < 0.01, 10, fn { ... })` that binds a Rust macro to make it something like `let mut counter = 0; while delta < 0.01 && counter < 10 { ...; counter = counter + 1; }` and `while delta < 0.01 { ... } limit 10 { ... }` would tack on an `if counter == 10 { ... }` afterwards). Somewhat roundabout, but extensible.

And that's it. Everything else (which is still a lot) would be implemented on top of this syntax, and would not be a breaking change when added. There are some conventions that I am already thinking about, however.

* Constructor functions should be named identically to the type they are creating, so creating an `i32` would be done with `i32(5)` or `5.i32()`. For the method syntax, to also make getters/setters, which are useful when you want to drop old properties but keep the old access pattern around during a deprecation period, or to annotate those accesses with logging, etc, I want to make it so a method syntax call with only a single argument can be done without the parens, meaning `5.i32` should also work. This makes defining units in Alan much easier, eg `3.km` reads pretty clearly *and* is converting the `3` into the `km` type (supposing one exists).
* Constructor functions for generic types should therefore be generic functions, and I think that makes sense, too, because otherwise how would the constructor know what type is going into the inner value?
* If a getter function exists for a type that covers up its property, how can that property be accessed? Well, only that getter function would be able to access it, because function dispatch within a function should *always* exclude itself from the list of functions it can dispatch to.
* All primitive types should be lowercase, `i32`, `bool`, `string`, etc. Similarly all functions should be lowercase, `map`, `get`, `set`, etc. Meanwhile generic types (which are also compile-time functions) should be capitalized, so `Array<T>`, `Add<A: Int, B: Int>`, etc. And interfaces should also be capitalized *and* be adjectives, `Stringifiable`, `Orderable`, `Iterable`, etc. This is kinda the opposite of English, as primitives and functions would be referring to a concrete "thing" while generic types and interfaces are referring to categories of things, but this both better matches conventions in other languages and reduces the amount of capitalization you need to write in your code.

## Affected Components

The entirety of the project, parser, compile stages, and generated output are all on the table.

## Expected Timeline

Before the end of summer.

